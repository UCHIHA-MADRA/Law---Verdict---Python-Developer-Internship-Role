{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602de84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install selenium pandas opencv-python pillow pytesseract requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f3321",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install Chrome and ChromeDriver for Colab\n",
    "!apt-get update\n",
    "!apt-get install -y chromium-browser chromium-chromedriver\n",
    "!apt-get install -y tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c140c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import the scraper class (copy the main script into a file first)\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887e9ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Rajasthan High Court Judgment Scraper\n",
    "Incrementally downloads judgments from https://hcraj.nic.in/cishcraj-jdp/JudgementFilters/\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "class RajasthanHCJudgmentScraper:\n",
    "    def __init__(self, download_dir: str = \"rajasthan_hc_judgments\"):\n",
    "        self.base_url = \"https://hcraj.nic.in/cishcraj-jdp/JudgementFilters/\"\n",
    "        self.download_dir = Path(download_dir)\n",
    "        self.pdf_dir = self.download_dir / \"pdfs\"\n",
    "        self.csv_file = self.download_dir / \"judgments.csv\"\n",
    "        self.state_file = self.download_dir / \"scraper_state.json\"\n",
    "        \n",
    "        # Create directories\n",
    "        self.download_dir.mkdir(exist_ok=True)\n",
    "        self.pdf_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Initialize state\n",
    "        self.downloaded_judgments = self.load_state()\n",
    "        \n",
    "        # Setup Chrome options\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument(\"--headless\")  # Remove for debugging\n",
    "        self.chrome_options.add_argument(\"--no-sandbox\")\n",
    "        self.chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        self.chrome_options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": str(self.pdf_dir.absolute()),\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"plugins.always_open_pdf_externally\": True\n",
    "        })\n",
    "        \n",
    "    def load_state(self) -> Dict:\n",
    "        \"\"\"Load previously downloaded judgment IDs and metadata\"\"\"\n",
    "        if self.state_file.exists():\n",
    "            with open(self.state_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {\"downloaded_ids\": set(), \"last_run_date\": None}\n",
    "    \n",
    "    def save_state(self):\n",
    "        \"\"\"Save current state to file\"\"\"\n",
    "        state_to_save = {\n",
    "            \"downloaded_ids\": list(self.downloaded_judgments[\"downloaded_ids\"]),\n",
    "            \"last_run_date\": self.downloaded_judgments[\"last_run_date\"]\n",
    "        }\n",
    "        with open(self.state_file, 'w') as f:\n",
    "            json.dump(state_to_save, f, indent=2)\n",
    "    \n",
    "    def generate_judgment_id(self, judgment_data: Dict) -> str:\n",
    "        \"\"\"Generate unique ID for judgment based on key fields\"\"\"\n",
    "        id_string = f\"{judgment_data.get('case_number', '')}_{judgment_data.get('judgment_date', '')}_{judgment_data.get('judge_name', '')}\"\n",
    "        return hashlib.md5(id_string.encode()).hexdigest()\n",
    "    \n",
    "    def solve_captcha(self, captcha_image_element) -> str:\n",
    "        \"\"\"\n",
    "        Simple captcha solver using OCR\n",
    "        This is a basic implementation - may need refinement based on captcha complexity\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Take screenshot of captcha\n",
    "            captcha_image_element.screenshot(\"temp_captcha.png\")\n",
    "            \n",
    "            # Load and preprocess image\n",
    "            img = cv2.imread(\"temp_captcha.png\")\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Apply preprocessing to improve OCR accuracy\n",
    "            # Remove noise\n",
    "            denoised = cv2.medianBlur(gray, 3)\n",
    "            \n",
    "            # Threshold to get binary image\n",
    "            _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            \n",
    "            # OCR with specific configuration for captcha\n",
    "            custom_config = r'--oem 3 --psm 7 -c tesseract_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "            captcha_text = pytesseract.image_to_string(thresh, config=custom_config).strip()\n",
    "            \n",
    "            # Clean up\n",
    "            os.remove(\"temp_captcha.png\")\n",
    "            \n",
    "            # Basic validation - captchas are usually 4-6 characters\n",
    "            if len(captcha_text) >= 3 and captcha_text.isalnum():\n",
    "                return captcha_text\n",
    "            else:\n",
    "                return \"\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error solving captcha: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def setup_driver(self) -> webdriver.Chrome:\n",
    "        \"\"\"Initialize Chrome WebDriver\"\"\"\n",
    "        return webdriver.Chrome(options=self.chrome_options)\n",
    "    \n",
    "    def fill_form_and_submit(self, driver: webdriver.Chrome, from_date: str, to_date: str, max_retries: int = 3) -> bool:\n",
    "        \"\"\"Fill the judgment search form and submit\"\"\"\n",
    "        try:\n",
    "            # Wait for page to load\n",
    "            WebDriverWait(driver, 10).wait(\n",
    "                EC.presence_of_element_located((By.NAME, \"fromDate\"))\n",
    "            )\n",
    "            \n",
    "            # Fill from date\n",
    "            from_date_field = driver.find_element(By.NAME, \"fromDate\")\n",
    "            from_date_field.clear()\n",
    "            from_date_field.send_keys(from_date)\n",
    "            \n",
    "            # Fill to date\n",
    "            to_date_field = driver.find_element(By.NAME, \"toDate\")\n",
    "            to_date_field.clear()\n",
    "            to_date_field.send_keys(to_date)\n",
    "            \n",
    "            # Set reportable judgment to YES\n",
    "            try:\n",
    "                reportable_dropdown = Select(driver.find_element(By.NAME, \"reportable\"))\n",
    "                reportable_dropdown.select_by_value(\"Y\")\n",
    "            except:\n",
    "                print(\"Could not find reportable judgment dropdown\")\n",
    "            \n",
    "            # Handle captcha with retries\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    captcha_img = driver.find_element(By.XPATH, \"//img[contains(@src, 'captcha')]\")\n",
    "                    captcha_text = self.solve_captcha(captcha_img)\n",
    "                    \n",
    "                    if captcha_text:\n",
    "                        captcha_field = driver.find_element(By.NAME, \"captcha\")\n",
    "                        captcha_field.clear()\n",
    "                        captcha_field.send_keys(captcha_text)\n",
    "                        \n",
    "                        # Submit form\n",
    "                        submit_btn = driver.find_element(By.XPATH, \"//input[@type='submit' or @value='Search']\")\n",
    "                        submit_btn.click()\n",
    "                        \n",
    "                        # Check if submission was successful\n",
    "                        time.sleep(3)\n",
    "                        if \"No records found\" not in driver.page_source and \"Invalid captcha\" not in driver.page_source.lower():\n",
    "                            return True\n",
    "                        else:\n",
    "                            print(f\"Captcha attempt {attempt + 1} failed, retrying...\")\n",
    "                            driver.refresh()\n",
    "                            time.sleep(2)\n",
    "                    else:\n",
    "                        print(f\"Could not solve captcha, attempt {attempt + 1}\")\n",
    "                        driver.refresh()\n",
    "                        time.sleep(2)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in captcha attempt {attempt + 1}: {e}\")\n",
    "                    driver.refresh()\n",
    "                    time.sleep(2)\n",
    "            \n",
    "            print(\"Failed to solve captcha after all attempts\")\n",
    "            return False\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error filling form: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def extract_judgment_data(self, driver: webdriver.Chrome) -> List[Dict]:\n",
    "        \"\"\"Extract judgment data from results table\"\"\"\n",
    "        judgments = []\n",
    "        \n",
    "        try:\n",
    "            # Wait for results table\n",
    "            WebDriverWait(driver, 10).wait(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "            )\n",
    "            \n",
    "            # Find the results table\n",
    "            tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "            results_table = None\n",
    "            \n",
    "            for table in tables:\n",
    "                if \"S.No.\" in table.text or \"Case Number\" in table.text:\n",
    "                    results_table = table\n",
    "                    break\n",
    "            \n",
    "            if not results_table:\n",
    "                print(\"Could not find results table\")\n",
    "                return judgments\n",
    "            \n",
    "            # Extract table headers\n",
    "            headers = []\n",
    "            header_row = results_table.find_element(By.TAG_NAME, \"tr\")\n",
    "            for th in header_row.find_elements(By.TAG_NAME, \"th\"):\n",
    "                headers.append(th.text.strip())\n",
    "            \n",
    "            # Extract data rows\n",
    "            rows = results_table.find_elements(By.TAG_NAME, \"tr\")[1:]  # Skip header\n",
    "            \n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cells) < len(headers):\n",
    "                    continue\n",
    "                \n",
    "                judgment_data = {}\n",
    "                for i, cell in enumerate(cells):\n",
    "                    if i < len(headers):\n",
    "                        judgment_data[headers[i]] = cell.text.strip()\n",
    "                \n",
    "                # Look for PDF download link\n",
    "                pdf_links = row.find_elements(By.XPATH, \".//a[contains(@href, '.pdf') or contains(text(), 'View') or contains(text(), 'Download')]\")\n",
    "                if pdf_links:\n",
    "                    judgment_data['pdf_url'] = pdf_links[0].get_attribute('href')\n",
    "                else:\n",
    "                    judgment_data['pdf_url'] = \"\"\n",
    "                \n",
    "                judgments.append(judgment_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting judgment data: {e}\")\n",
    "        \n",
    "        return judgments\n",
    "    \n",
    "    def download_pdf(self, url: str, filename: str) -> bool:\n",
    "        \"\"\"Download PDF from URL\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            pdf_path = self.pdf_dir / filename\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading PDF {filename}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def generate_pdf_filename(self, judgment_data: Dict) -> str:\n",
    "        \"\"\"Generate safe filename for PDF\"\"\"\n",
    "        case_num = judgment_data.get('Case Number', 'Unknown').replace('/', '_').replace('\\\\', '_')\n",
    "        date = judgment_data.get('Judgment Date', '').replace('/', '_')\n",
    "        return f\"{case_num}_{date}.pdf\"\n",
    "    \n",
    "    def scrape_judgments(self, from_date: str, to_date: str) -> List[Dict]:\n",
    "        \"\"\"Main scraping function\"\"\"\n",
    "        print(f\"Scraping judgments from {from_date} to {to_date}\")\n",
    "        \n",
    "        driver = self.setup_driver()\n",
    "        all_judgments = []\n",
    "        \n",
    "        try:\n",
    "            driver.get(self.base_url)\n",
    "            \n",
    "            if self.fill_form_and_submit(driver, from_date, to_date):\n",
    "                judgments = self.extract_judgment_data(driver)\n",
    "                \n",
    "                for judgment in judgments:\n",
    "                    judgment_id = self.generate_judgment_id(judgment)\n",
    "                    \n",
    "                    # Skip if already downloaded\n",
    "                    if judgment_id in self.downloaded_judgments[\"downloaded_ids\"]:\n",
    "                        print(f\"Skipping already downloaded judgment: {judgment.get('Case Number', 'Unknown')}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Download PDF if URL exists\n",
    "                    pdf_filename = \"\"\n",
    "                    if judgment.get('pdf_url'):\n",
    "                        pdf_filename = self.generate_pdf_filename(judgment)\n",
    "                        if self.download_pdf(judgment['pdf_url'], pdf_filename):\n",
    "                            judgment['pdf_filename'] = pdf_filename\n",
    "                            print(f\"Downloaded: {pdf_filename}\")\n",
    "                        else:\n",
    "                            judgment['pdf_filename'] = \"Download_Failed\"\n",
    "                    else:\n",
    "                        judgment['pdf_filename'] = \"No_PDF_URL\"\n",
    "                    \n",
    "                    # Mark as downloaded\n",
    "                    self.downloaded_judgments[\"downloaded_ids\"].add(judgment_id)\n",
    "                    all_judgments.append(judgment)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during scraping: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            driver.quit()\n",
    "        \n",
    "        return all_judgments\n",
    "    \n",
    "    def save_to_csv(self, judgments: List[Dict]):\n",
    "        \"\"\"Save judgments to CSV file\"\"\"\n",
    "        if not judgments:\n",
    "            print(\"No new judgments to save\")\n",
    "            return\n",
    "        \n",
    "        # Load existing data if CSV exists\n",
    "        existing_df = pd.DataFrame()\n",
    "        if self.csv_file.exists():\n",
    "            try:\n",
    "                existing_df = pd.read_csv(self.csv_file)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Create new DataFrame\n",
    "        new_df = pd.DataFrame(judgments)\n",
    "        \n",
    "        # Combine and save\n",
    "        if not existing_df.empty:\n",
    "            combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = new_df\n",
    "        \n",
    "        combined_df.to_csv(self.csv_file, index=False)\n",
    "        print(f\"Saved {len(judgments)} new judgments to {self.csv_file}\")\n",
    "    \n",
    "    def run_incremental_scrape(self):\n",
    "        \"\"\"Run incremental scraping for last 10 days\"\"\"\n",
    "        today = datetime.now()\n",
    "        from_date_obj = today - timedelta(days=10)\n",
    "        \n",
    "        from_date = from_date_obj.strftime(\"%d/%m/%Y\")\n",
    "        to_date = today.strftime(\"%d/%m/%Y\")\n",
    "        \n",
    "        print(f\"Running incremental scrape from {from_date} to {to_date}\")\n",
    "        \n",
    "        judgments = self.scrape_judgments(from_date, to_date)\n",
    "        \n",
    "        if judgments:\n",
    "            self.save_to_csv(judgments)\n",
    "        \n",
    "        # Update state\n",
    "        self.downloaded_judgments[\"last_run_date\"] = today.isoformat()\n",
    "        self.save_state()\n",
    "        \n",
    "        print(f\"Scraping completed. Downloaded {len(judgments)} new judgments.\")\n",
    "        return judgments\n",
    "\n",
    "# Bonus: Supreme Court Captcha Solver\n",
    "class SCICaptchaSolver:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def preprocess_captcha_image(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Preprocess captcha image for better OCR\"\"\"\n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            img = np.array(Image.open(image_path))\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = img\n",
    "        \n",
    "        # Resize image for better OCR\n",
    "        height, width = gray.shape\n",
    "        if height < 50:\n",
    "            scale_factor = 50 / height\n",
    "            new_width = int(width * scale_factor)\n",
    "            gray = cv2.resize(gray, (new_width, 50))\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        \n",
    "        # Apply threshold\n",
    "        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Morphological operations to clean up\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def solve_sci_captcha(self, captcha_image_path: str) -> str:\n",
    "        \"\"\"Solve Supreme Court captcha\"\"\"\n",
    "        try:\n",
    "            processed_img = self.preprocess_captcha_image(captcha_image_path)\n",
    "            \n",
    "            # OCR configuration for Supreme Court captcha\n",
    "            custom_config = r'--oem 3 --psm 8 -c tesseract_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "            \n",
    "            # Try OCR\n",
    "            captcha_text = pytesseract.image_to_string(processed_img, config=custom_config).strip()\n",
    "            \n",
    "            # Clean the result\n",
    "            captcha_text = re.sub(r'[^A-Z0-9]', '', captcha_text.upper())\n",
    "            \n",
    "            return captcha_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error solving SCI captcha: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the scraper\"\"\"\n",
    "    print(\"Rajasthan High Court Judgment Scraper\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize scraper\n",
    "    scraper = RajasthanHCJudgmentScraper()\n",
    "    \n",
    "    # Run incremental scrape\n",
    "    try:\n",
    "        judgments = scraper.run_incremental_scrape()\n",
    "        print(f\"\\n‚úÖ Successfully processed {len(judgments)} judgments\")\n",
    "        print(f\"üìÅ Files saved in: {scraper.download_dir}\")\n",
    "        print(f\"üìÑ CSV file: {scraper.csv_file}\")\n",
    "        print(f\"üìö PDFs saved in: {scraper.pdf_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running scraper: {e}\")\n",
    "        \n",
    "    # Bonus: SCI Captcha solver demo\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Supreme Court Captcha Solver (Bonus)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    sci_solver = SCICaptchaSolver()\n",
    "    print(\"SCI Captcha solver initialized. Use sci_solver.solve_sci_captcha('path_to_captcha.png')\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fce4c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Initialize the scraper\n",
    "print(\"üöÄ Initializing Rajasthan HC Scraper...\")\n",
    "scraper = RajasthanHCJudgmentScraper(download_dir=\"rajasthan_hc_judgments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530ede1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Run incremental scraping (default: last 10 days)\n",
    "print(\"\\nüì• Running incremental scrape for last 10 days...\")\n",
    "try:\n",
    "    judgments = scraper.run_incremental_scrape()\n",
    "    print(f\"‚úÖ Successfully downloaded {len(judgments)} new judgments\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f8f59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Display results\n",
    "if os.path.exists(\"rajasthan_hc_judgments/judgments.csv\"):\n",
    "    df = pd.read_csv(\"rajasthan_hc_judgments/judgments.csv\")\n",
    "    print(f\"\\nüìä Total judgments in database: {len(df)}\")\n",
    "    print(\"\\nüìã Sample data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Display statistics\n",
    "    print(\"\\nüìà Statistics:\")\n",
    "    print(f\"‚Ä¢ Total judgments: {len(df)}\")\n",
    "    print(f\"‚Ä¢ PDFs downloaded: {len(df[df['pdf_filename'].str.contains('.pdf', na=False)])}\")\n",
    "    print(f\"‚Ä¢ Failed downloads: {len(df[df['pdf_filename'] == 'Download_Failed'])}\")\n",
    "    print(f\"‚Ä¢ No PDF URL: {len(df[df['pdf_filename'] == 'No_PDF_URL'])}\")\n",
    "else:\n",
    "    print(\"‚ùå No CSV file found. Scraping may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecb14b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Custom date range scraping\n",
    "print(\"\\nüóìÔ∏è Custom date range example:\")\n",
    "from_date = \"01/09/2024\"  # DD/MM/YYYY format\n",
    "to_date = \"11/09/2024\"\n",
    "\n",
    "print(f\"Scraping from {from_date} to {to_date}...\")\n",
    "try:\n",
    "    custom_judgments = scraper.scrape_judgments(from_date, to_date)\n",
    "    print(f\"‚úÖ Found {len(custom_judgments)} judgments in custom range\")\n",
    "    \n",
    "    if custom_judgments:\n",
    "        scraper.save_to_csv(custom_judgments)\n",
    "        scraper.downloaded_judgments[\"last_run_date\"] = datetime.now().isoformat()\n",
    "        scraper.save_state()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Custom scraping error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b5f4fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Bonus: SCI Captcha Solver Demo\n",
    "print(\"\\nüéØ Supreme Court Captcha Solver (Bonus):\")\n",
    "sci_solver = SCICaptchaSolver()\n",
    "\n",
    "# Example usage (you would need to provide an actual captcha image)\n",
    "# captcha_result = sci_solver.solve_sci_captcha(\"captcha_image.png\")\n",
    "# print(f\"Captcha solved: {captcha_result}\")\n",
    "\n",
    "print(\"\\nüìÅ File structure:\")\n",
    "!ls -la rajasthan_hc_judgments/\n",
    "print(\"\\nüìö PDFs downloaded:\")\n",
    "!ls -la rajasthan_hc_judgments/pdfs/ | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1002e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Data analysis examples\n",
    "if os.path.exists(\"rajasthan_hc_judgments/judgments.csv\"):\n",
    "    df = pd.read_csv(\"rajasthan_hc_judgments/judgments.csv\")\n",
    "    \n",
    "    print(\"\\nüìä Data Analysis:\")\n",
    "    \n",
    "    # Check for date column variations\n",
    "    date_columns = [col for col in df.columns if 'date' in col.lower()]\n",
    "    print(f\"Date columns found: {date_columns}\")\n",
    "    \n",
    "    # Show unique values in key columns\n",
    "    for col in df.columns[:5]:  # First 5 columns\n",
    "        print(f\"\\nüîç Column '{col}' - Unique values: {df[col].nunique()}\")\n",
    "        if df[col].nunique() < 10:\n",
    "            print(f\"   Values: {df[col].unique()[:5]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Notebook execution completed!\")\n",
    "print(\"\\nüìñ How to use:\")\n",
    "print(\"1. The scraper runs incrementally - it remembers what it has downloaded\")\n",
    "print(\"2. Run the scraper daily to get new judgments\")\n",
    "print(\"3. All data is saved in 'rajasthan_hc_judgments/' folder\")\n",
    "print(\"4. CSV contains all metadata, PDFs are in 'pdfs/' subfolder\")\n",
    "print(\"5. State is tracked in 'scraper_state.json'\")\n",
    "\n",
    "# === TROUBLESHOOTING SECTION ===\n",
    "print(\"\\nüîß Troubleshooting Tips:\")\n",
    "print(\"1. If captcha solving fails, the script will retry 3 times\")\n",
    "print(\"2. For Colab, make sure to install all dependencies\")\n",
    "print(\"3. Check internet connection if downloads fail\")\n",
    "print(\"4. Captcha OCR may need fine-tuning based on actual captcha images\")\n",
    "print(\"5. The script handles various table formats automatically\")\n",
    "\n",
    "# === MANUAL CAPTCHA FALLBACK ===\n",
    "def manual_run_with_captcha():\n",
    "    \"\"\"\n",
    "    Manual mode where user can input captcha\n",
    "    Use this if automated captcha solving doesn't work\n",
    "    \"\"\"\n",
    "    print(\"\\nüîß Manual captcha mode available - modify the scraper to accept manual input\")\n",
    "    print(\"Replace the solve_captcha method with manual input for testing\")\n",
    "    \n",
    "    # Example manual captcha input modification:\n",
    "    manual_code = \"\"\"\n",
    "    def solve_captcha_manual(self, captcha_image_element) -> str:\n",
    "        captcha_image_element.screenshot(\"captcha_display.png\")\n",
    "        from IPython.display import Image, display\n",
    "        display(Image(\"captcha_display.png\"))\n",
    "        return input(\"Please enter the captcha: \").strip()\n",
    "    \"\"\"\n",
    "    print(\"Replace solve_captcha method with manual input if needed:\")\n",
    "    print(manual_code)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
